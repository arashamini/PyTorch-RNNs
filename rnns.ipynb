{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rnns.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sqlNTJXML5sw",
        "outputId": "c6b82531-ba28-4d25-c687-4f73e2f09ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "print_step = 200\n",
        "\n",
        "num_layers = 3\n",
        "input_size = 28\n",
        "time_step = 28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "\n",
        "# Reproducibility\n",
        "seed = 99\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST('data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gBTxJp-uLrRd"
      },
      "source": [
        "## Long Short-term Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3tRIy9LP888",
        "colab_type": "text"
      },
      "source": [
        "$ \\begin{array}{ll}\n",
        "i_{t} = \\sigma(W_{ii} x_{t} + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
        "f_{t} = \\sigma(W_{if} x_{t} + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
        "o_{t} = \\sigma(W_{io} x_{t} + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
        "c_{t} = f_{t} \\odot c_{t-1} + i_{t} \\odot \\tanh(W_{ic} x_{t} + b_{ic} + W_{hc} h_{t-1} + b_{hc}) \\\\\n",
        "h_{t} = o_{t} \\odot \\tanh(c_{t}) \\\\\n",
        "\\end{array} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tc-eQZHiNV_H",
        "colab": {}
      },
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    \"\"\"Long short-term memory (LSTM) cell\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.weight_ih = nn.Parameter(torch.Tensor(input_size, hidden_size * 4))\n",
        "        self.weight_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size * 4))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(hidden_size * 4))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(hidden_size * 4))\n",
        "        self.init_parameters()\n",
        "\n",
        "    def init_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for param in self.parameters():\n",
        "            nn.init.uniform_(param, -stdv, stdv)\n",
        "\n",
        "    def forward(self, x, init_states):\n",
        "        h_t_minus_1, c_t_minus_1 = init_states\n",
        "        gates = torch.mm(x, self.weight_ih) + self.bias_ih + torch.mm(h_t_minus_1, self.weight_hh) + self.bias_hh\n",
        "        inputgate, forgetgate, cell, outputgate = gates.chunk(4, dim=1)\n",
        "        c = (torch.sigmoid(forgetgate) * c_t_minus_1) + (torch.sigmoid(inputgate) * torch.tanh(cell))\n",
        "        h = torch.sigmoid(outputgate) * torch.tanh(c)\n",
        "        return (h, c)\n",
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    \"\"\"Multi-layer long short-term memory (LSTM)\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, batch_first=False):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        layers = [LSTMCell(input_size, hidden_size)]\n",
        "        for i in range(num_layers - 1):\n",
        "            layers += [LSTMCell(hidden_size, hidden_size)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, init_states=None):\n",
        "        # Input and output size: (seq_length, batch_size, input_size)\n",
        "        # States size: (num_layers, batch_size, hidden_size)\n",
        "        if self.batch_first:\n",
        "            x = x.transpose(0, 1)\n",
        "\n",
        "        self.h = torch.zeros(x.size(0), self.num_layers, x.size(1), self.hidden_size).to(x.device)\n",
        "        self.c = torch.zeros(x.size(0), self.num_layers, x.size(1), self.hidden_size).to(x.device)\n",
        "        if init_states is not None:\n",
        "            self.h[0], self.c[0] = init_states\n",
        "\n",
        "        inputs = x\n",
        "        for i, cell in enumerate(self.net):  # Layers\n",
        "            h_t, c_t = self.h[0, i].clone(), self.c[0, i].clone()\n",
        "            for t in range(x.size(0)):  # Sequences\n",
        "                h_t, c_t = cell(inputs[t], (h_t, c_t))\n",
        "                self.h[t, i], self.c[t, i] = h_t, c_t\n",
        "            inputs = self.h[:, i].clone()\n",
        "\n",
        "        if self.batch_first:\n",
        "            return self.h[:, -1].transpose(0, 1), (self.h[-1], self.c[-1])\n",
        "\n",
        "        return self.h[:, -1], (self.h[-1], self.c[-1])\n",
        "\n",
        "        # if init_states is not None:\n",
        "        #     h_0, c_0 = init_states\n",
        "        # else:\n",
        "        #     h_0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(x.device)\n",
        "        #     c_0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(x.device)\n",
        "        #\n",
        "        # inputs, outputs, h, c = x, [], [], []\n",
        "        # for i, cell in enumerate(self.net):  # Layers\n",
        "        #     h_t, c_t = h_0[i], c_0[i]\n",
        "        #     for t in range(x.size(0)):  # Sequences\n",
        "        #         h_t, c_t = cell(inputs[t], (h_t, c_t))\n",
        "        #         outputs += [h_t]\n",
        "        #     inputs, outputs = outputs, []\n",
        "        #     h += [h_t]\n",
        "        #     c += [c_t]\n",
        "        #\n",
        "        # if self.batch_first:\n",
        "        #     return torch.stack(inputs).transpose(0, 1), (torch.stack(h), torch.stack(c))\n",
        "        #\n",
        "        # return torch.stack(inputs), (torch.stack(h), torch.stack(c))\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x, None)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uGvVPgWO8Oia",
        "outputId": "645dfc3f-31b9-4219-f0b4-86d2a58b90c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "steps = len(train_loader)\n",
        "test_total = len(test_loader.dataset)\n",
        "\n",
        "print('Train on {} samples, test on {} samples'.format(len(train_loader.dataset), test_total))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "\n",
        "    running_loss = 0.0\n",
        "    corrects = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.view(-1, time_step, input_size).to(device)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        corrects += torch.sum(preds == labels).item()\n",
        "        total += inputs.size(0)\n",
        "\n",
        "        if (i + 1) % print_step == 0 or (i + 1) == steps:\n",
        "            # Test phase\n",
        "            test_running_loss = 0.0\n",
        "            test_corrects = 0\n",
        "\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs = inputs.view(-1, time_step, input_size).to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Prevent tracking history\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    test_running_loss += loss.item() * inputs.size(0)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    test_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "            train_acc = corrects / total\n",
        "            train_loss = running_loss / total\n",
        "            test_acc = test_corrects / test_total\n",
        "            test_loss = test_running_loss / test_total\n",
        "\n",
        "            print('step: {}/{} - loss: {:.4f} - acc: {:.3f} - test_loss: {:.4f} - test_acc: {:.3f}'.format(\n",
        "                i + 1, steps, train_loss, train_acc, test_loss, test_acc))\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print('Training complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n",
        "\n",
        "inputs = inputs.cpu().numpy()\n",
        "preds = preds.cpu().numpy()\n",
        "labels = labels.cpu().numpy()\n",
        "n_rows, n_cols = (2, 8)\n",
        "plt.figure(figsize=(n_cols, n_rows))\n",
        "for i in range(n_rows * n_cols):\n",
        "    plt.subplot(n_rows, n_cols, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.title(preds[i])\n",
        "    plt.imshow(inputs[i], cmap='gray')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, test on 10000 samples\n",
            "Epoch 1/5\n",
            "step: 200/469 - loss: 1.0843 - acc: 0.610 - test_loss: 0.4426 - test_acc: 0.857\n",
            "step: 400/469 - loss: 0.6814 - acc: 0.763 - test_loss: 0.1894 - test_acc: 0.944\n",
            "step: 469/469 - loss: 0.6086 - acc: 0.790 - test_loss: 0.1793 - test_acc: 0.949\n",
            "Epoch 2/5\n",
            "step: 200/469 - loss: 0.1559 - acc: 0.953 - test_loss: 0.1368 - test_acc: 0.961\n",
            "step: 400/469 - loss: 0.1360 - acc: 0.959 - test_loss: 0.1056 - test_acc: 0.968\n",
            "step: 469/469 - loss: 0.1315 - acc: 0.961 - test_loss: 0.1219 - test_acc: 0.964\n",
            "Epoch 3/5\n",
            "step: 200/469 - loss: 0.0935 - acc: 0.973 - test_loss: 0.1032 - test_acc: 0.970\n",
            "step: 400/469 - loss: 0.0863 - acc: 0.975 - test_loss: 0.0737 - test_acc: 0.978\n",
            "step: 469/469 - loss: 0.0839 - acc: 0.975 - test_loss: 0.0786 - test_acc: 0.979\n",
            "Epoch 4/5\n",
            "step: 200/469 - loss: 0.0647 - acc: 0.981 - test_loss: 0.0834 - test_acc: 0.975\n",
            "step: 400/469 - loss: 0.0638 - acc: 0.981 - test_loss: 0.0645 - test_acc: 0.981\n",
            "step: 469/469 - loss: 0.0625 - acc: 0.981 - test_loss: 0.0604 - test_acc: 0.982\n",
            "Epoch 5/5\n",
            "step: 200/469 - loss: 0.0488 - acc: 0.985 - test_loss: 0.0514 - test_acc: 0.983\n",
            "step: 400/469 - loss: 0.0507 - acc: 0.984 - test_loss: 0.0542 - test_acc: 0.983\n",
            "step: 469/469 - loss: 0.0507 - acc: 0.985 - test_loss: 0.0539 - test_acc: 0.983\n",
            "Training complete in 3m 36s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACJCAYAAAAYG/NUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndEyEEEII4Rv/D/qzhhSY4STEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x144 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e0XE2VzILuGN"
      },
      "source": [
        "## Gated Recurrent Unit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei6IDHKxP89C",
        "colab_type": "text"
      },
      "source": [
        "$ \\begin{array}{ll}\n",
        "r_{t} = \\sigma(W_{ir} x_{t} + b_{ir} + W_{hr} h_{t-1} + b_{hr}) \\\\\n",
        "z_{t} = \\sigma(W_{iz} x_{t} + b_{iz} + W_{hz} h_{t-1} + b_{hz}) \\\\\n",
        "\\tilde{h}_{t} = \\tanh(W_{ih} x_{t} + b_{ih} + W(r_{t} \\odot h_{t-1})) \\\\\n",
        "h_{t} = (1 - z_{t}) \\odot h_{t-1} + z_{t} \\odot \\tilde{h}_{t}\n",
        "\\end{array} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4HSGoWtGP89C",
        "colab": {}
      },
      "source": [
        "class GRUCell(nn.Module):\n",
        "    \"\"\"Gated recurrent unit (GRU) cell\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.weight_ih = nn.Parameter(torch.Tensor(input_size, hidden_size * 3))\n",
        "        self.weight_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size * 3))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(hidden_size * 3))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(hidden_size * 3))\n",
        "        self.init_parameters()\n",
        "\n",
        "    def init_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for param in self.parameters():\n",
        "            nn.init.uniform_(param, -stdv, stdv)\n",
        "\n",
        "    def forward(self, x, h_t_minus_1):\n",
        "        idx = self.hidden_size * 2\n",
        "        gates_ih = torch.mm(x, self.weight_ih) + self.bias_ih\n",
        "        gates_hh = torch.mm(h_t_minus_1, self.weight_hh[:, :idx]) + self.bias_hh[:idx]\n",
        "        resetgate_i, updategate_i, output_i = gates_ih.chunk(3, dim=1)\n",
        "        resetgate_h, updategate_h = gates_hh.chunk(2, dim=1)\n",
        "        r = torch.sigmoid(resetgate_i + resetgate_h)\n",
        "        z = torch.sigmoid(updategate_i + updategate_h)\n",
        "        h_tilde = torch.tanh(output_i + (torch.mm((r * h_t_minus_1), self.weight_hh[:, idx:]) + self.bias_hh[idx:]))\n",
        "        h = (1 - z) * h_t_minus_1 + z * h_tilde\n",
        "        return h\n",
        "\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    \"\"\"Multi-layer gated recurrent unit (GRU)\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, batch_first=False):\n",
        "        super(GRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        layers = [GRUCell(input_size, hidden_size)]\n",
        "        for i in range(num_layers - 1):\n",
        "            layers += [GRUCell(hidden_size, hidden_size)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, init_state=None):\n",
        "        # Input and output size: (seq_length, batch_size, input_size)\n",
        "        # State size: (num_layers, batch_size, hidden_size)\n",
        "        if self.batch_first:\n",
        "            x = x.transpose(0, 1)\n",
        "\n",
        "        self.h = torch.zeros(x.size(0), self.num_layers, x.size(1), self.hidden_size).to(x.device)\n",
        "        if init_state is not None:\n",
        "            self.h[0, :] = init_state\n",
        "\n",
        "        inputs = x\n",
        "        for i, cell in enumerate(self.net):  # Layers\n",
        "            h_t = self.h[0, i].clone()\n",
        "            for t in range(x.size(0)):  # Sequences\n",
        "                h_t = cell(inputs[t], h_t)\n",
        "                self.h[t, i] = h_t\n",
        "            inputs = self.h[:, i].clone()\n",
        "\n",
        "        if self.batch_first:\n",
        "            return self.h[:, -1].transpose(0, 1), self.h[-1]\n",
        "\n",
        "        return self.h[:, -1], self.h[-1]\n",
        "\n",
        "        # if init_state is not None:\n",
        "        #     h_0 = init_state\n",
        "        # else:\n",
        "        #     h_0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(x.device)\n",
        "        #\n",
        "        # inputs, outputs, h = x, [], []\n",
        "        # for i, cell in enumerate(self.net):  # Layers\n",
        "        #     h_t = h_0[i]\n",
        "        #     for t in range(x.size(0)):  # Sequences\n",
        "        #         h_t = cell(inputs[t], h_t)\n",
        "        #         outputs += [h_t]\n",
        "        #     inputs, outputs = outputs, []\n",
        "        #     h += [h_t]\n",
        "        #\n",
        "        # if self.batch_first:\n",
        "        #     return torch.stack(inputs).transpose(0, 1), torch.stack(h)\n",
        "        #\n",
        "        # return torch.stack(inputs), torch.stack(h)\n",
        "\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x, None)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cO32QdRDMrQ8",
        "outputId": "3cebfb88-7e5d-41b9-d82d-7336ffcf9219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "model = GRUModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "steps = len(train_loader)\n",
        "test_total = len(test_loader.dataset)\n",
        "\n",
        "print('Train on {} samples, test on {} samples'.format(len(train_loader.dataset), test_total))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "\n",
        "    running_loss = 0.0\n",
        "    corrects = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.view(-1, time_step, input_size).to(device)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        corrects += torch.sum(preds == labels).item()\n",
        "        total += inputs.size(0)\n",
        "\n",
        "        if (i + 1) % print_step == 0 or (i + 1) == steps:\n",
        "            # Test phase\n",
        "            test_running_loss = 0.0\n",
        "            test_corrects = 0\n",
        "\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs = inputs.view(-1, time_step, input_size).to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Prevent tracking history\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    test_running_loss += loss.item() * inputs.size(0)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    test_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "            train_acc = corrects / total\n",
        "            train_loss = running_loss / total\n",
        "            test_acc = test_corrects / test_total\n",
        "            test_loss = test_running_loss / test_total\n",
        "\n",
        "            print('step: {}/{} - loss: {:.4f} - acc: {:.3f} - test_loss: {:.4f} - test_acc: {:.3f}'.format(\n",
        "                i + 1, steps, train_loss, train_acc, test_loss, test_acc))\n",
        "\n",
        "elapsed_time = time.time() - start\n",
        "print('Training complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n",
        "\n",
        "inputs = inputs.cpu().numpy()\n",
        "preds = preds.cpu().numpy()\n",
        "labels = labels.cpu().numpy()\n",
        "n_rows, n_cols = (2, 8)\n",
        "plt.figure(figsize=(n_cols, n_rows))\n",
        "for i in range(n_rows * n_cols):\n",
        "    plt.subplot(n_rows, n_cols, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.title(preds[i])\n",
        "    plt.imshow(inputs[i], cmap='gray')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, test on 10000 samples\n",
            "Epoch 1/5\n",
            "step: 200/469 - loss: 0.8217 - acc: 0.720 - test_loss: 0.2869 - test_acc: 0.916\n",
            "step: 400/469 - loss: 0.5191 - acc: 0.828 - test_loss: 0.1661 - test_acc: 0.951\n",
            "step: 469/469 - loss: 0.4667 - acc: 0.845 - test_loss: 0.1462 - test_acc: 0.957\n",
            "Epoch 2/5\n",
            "step: 200/469 - loss: 0.1230 - acc: 0.962 - test_loss: 0.1115 - test_acc: 0.967\n",
            "step: 400/469 - loss: 0.1118 - acc: 0.966 - test_loss: 0.0934 - test_acc: 0.972\n",
            "step: 469/469 - loss: 0.1079 - acc: 0.967 - test_loss: 0.0841 - test_acc: 0.974\n",
            "Epoch 3/5\n",
            "step: 200/469 - loss: 0.0781 - acc: 0.976 - test_loss: 0.0788 - test_acc: 0.977\n",
            "step: 400/469 - loss: 0.0751 - acc: 0.977 - test_loss: 0.0611 - test_acc: 0.981\n",
            "step: 469/469 - loss: 0.0734 - acc: 0.977 - test_loss: 0.0608 - test_acc: 0.982\n",
            "Epoch 4/5\n",
            "step: 200/469 - loss: 0.0528 - acc: 0.983 - test_loss: 0.0471 - test_acc: 0.985\n",
            "step: 400/469 - loss: 0.0516 - acc: 0.984 - test_loss: 0.0415 - test_acc: 0.989\n",
            "step: 469/469 - loss: 0.0512 - acc: 0.984 - test_loss: 0.0493 - test_acc: 0.986\n",
            "Epoch 5/5\n",
            "step: 200/469 - loss: 0.0371 - acc: 0.989 - test_loss: 0.0490 - test_acc: 0.985\n",
            "step: 400/469 - loss: 0.0404 - acc: 0.988 - test_loss: 0.0450 - test_acc: 0.987\n",
            "step: 469/469 - loss: 0.0415 - acc: 0.988 - test_loss: 0.0505 - test_acc: 0.984\n",
            "Training complete in 4m 32s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACJCAYAAAAYG/NUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x144 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}